{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amkPbyYfu0Wt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WfWfbya_u-Bp",
        "outputId": "68cd216f-d740-449f-d07c-4231ffb4f06f"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DKlZhl3nvBJv"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('drive/MyDrive/diabetes_prediction_dataset.csv', delimiter = ',', encoding ='UTF-8')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rtDfFiAawsf9"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H30tNeBXwwMk"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uDCywc21w0-k"
      },
      "outputs": [],
      "source": [
        "# check duplicate values\n",
        "print(df.duplicated().sum())\n",
        "# remove duplicate values\n",
        "df = df.drop_duplicates()\n",
        "print(\"______Removed Duplicate______\")\n",
        "print(df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g6zkPjPe0jlD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import Pipeline as imbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your data\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Encode categorical variables\n",
        "le = LabelEncoder()\n",
        "df['gender'] = le.fit_transform(df['gender'])\n",
        "df['smoking_history'] = le.fit_transform(df['smoking_history'])\n",
        "\n",
        "# Selecting features and target variable\n",
        "features = ['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
        "X = df[features]\n",
        "y = df['diabetes']\n",
        "\n",
        "# Define preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'hypertension', 'heart_disease']),\n",
        "        ('cat', OneHotEncoder(), ['gender', 'smoking_history'])\n",
        "    ])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Applying PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Plotting the cumulative explained variance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1),\n",
        "         pca.explained_variance_ratio_.cumsum(), marker='o', linestyle='--')\n",
        "plt.title('Explained Variance by Number of Principal Components')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.grid()\n",
        "\n",
        "# Find the index of the maximum cumulative explained variance\n",
        "max_index = pca.explained_variance_ratio_.cumsum().argmax()\n",
        "\n",
        "# Annotate the point with the highest cumulative explained variance\n",
        "plt.annotate(f'Max: PC {max_index + 1}',\n",
        "             xy=(max_index + 1, pca.explained_variance_ratio_.cumsum()[max_index]),\n",
        "             xytext=(max_index + 2, pca.explained_variance_ratio_.cumsum()[max_index] - 0.05),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='->', color='black'))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Printing explained variance ratios\n",
        "for i, ratio in enumerate(pca.explained_variance_ratio_.cumsum()):\n",
        "    print(f'Principal Component {i+1}: {ratio:.4f} cumulative explained variance')\n",
        "\n",
        "# Choose the number of components that explain most of the variance\n",
        "n_components = max_index + 1\n",
        "\n",
        "# Applying PCA with the optimal number of components\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Define resampling strategy\n",
        "over = SMOTE(sampling_strategy=0.1)\n",
        "under = RandomUnderSampler(sampling_strategy=0.5)\n",
        "\n",
        "# Create a pipeline that preprocesses the data, resamples data, and then trains a classifier\n",
        "clf = imbPipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('over', over),\n",
        "    ('under', under),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [50, 100, 200],\n",
        "    'classifier__max_depth': [None, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Now you can use clf for further training and model evaluation, e.g., using GridSearchCV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mXuEHLgP6E94"
      },
      "outputs": [],
      "source": [
        "# Compute the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "#Graph I.\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Graph II\n",
        "# Create a heatmap of the correlations with the target column\n",
        "corr = df.corr()\n",
        "target_corr = corr['diabetes'].drop('diabetes')\n",
        "\n",
        "# Sort correlation values in descending order\n",
        "target_corr_sorted = target_corr.sort_values(ascending=False)\n",
        "\n",
        "sns.set(font_scale=0.8)\n",
        "sns.set_style(\"white\")\n",
        "sns.set_palette(\"PuBuGn_d\")\n",
        "sns.heatmap(target_corr_sorted.to_frame(), cmap=\"coolwarm\", annot=True, fmt='.2f')\n",
        "plt.title('Correlation with Diabetes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y9ZoEabH7vB6"
      },
      "outputs": [],
      "source": [
        "# Histogram for age\n",
        "plt.hist(df['age'], bins=30, edgecolor='black')\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_ADf45BM-eXN"
      },
      "outputs": [],
      "source": [
        "# Bar plot for gender\n",
        "sns.countplot(x='gender', data=df)\n",
        "plt.title('Gender Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gmjzVibm_Ixc"
      },
      "outputs": [],
      "source": [
        "# Distribution plot for BMI\n",
        "sns.distplot(df['bmi'], bins=30)\n",
        "plt.title('BMI Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qarN-yGN_VXf"
      },
      "outputs": [],
      "source": [
        "# Count plots for binary variables\n",
        "for col in ['hypertension', 'heart_disease', 'diabetes']:\n",
        "    sns.countplot(x=col, data=df)\n",
        "    plt.title(f'{col} Distribution')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0hV5JIo__bci"
      },
      "outputs": [],
      "source": [
        "# Count plot of gender vs diabetes\n",
        "sns.countplot(x='gender', hue='diabetes', data=df)\n",
        "plt.title('Gender vs Diabetes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rN3uvdsk_fdv"
      },
      "outputs": [],
      "source": [
        "# Scatterplot Age vs BMI colored by Diabetes classification\n",
        "sns.scatterplot(x='age', y='bmi', hue='diabetes', data=df)\n",
        "plt.title('Age vs BMI')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TCECur0gw73C"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing and training the XGBoost model\n",
        "xgb_model = XGBClassifier(random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'XGBoost Accuracy: {accuracy:.4f}')\n",
        "print(f'XGBoost Classification Report:\\n{classification_report(y_test, y_pred)}')\n",
        "\n",
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Sgec-SC1xNJ5"
      },
      "outputs": [],
      "source": [
        "# Create Grid Search object\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
        "# Train the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the best model\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Model Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}